apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: collector-receiver-lb
  namespace: o11y
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.133.0
  config:
    exporters:
      loadbalancing/tailsampling:
        routing_key: "traceID"
        protocol:
          otlp:
            sending_queue:
              enabled: true
              num_consumers: 20
            tls:
              insecure: true
        resolver:
          k8s:
            ports:
            - 4317
            service: collector-tailsampling-collector.o11y
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 10s
          max_elapsed_time: 120s
        sending_queue:
          enabled: true
          num_consumers: 20
          queue_size: 50000
        timeout: 30s
      loadbalancing/spanmetrics:
        routing_key: "service"
        protocol:
          otlp:
            sending_queue:
              enabled: true
              num_consumers: 10
            tls:
              insecure: true
        resolver:
          k8s:
            ports:
            - 4317
            service: collector-spanmetrics-collector.o11y
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 10s
          max_elapsed_time: 120s
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
        timeout: 30s
      loadbalancing/servicegraph:
        routing_key: "traceID"
        protocol:
          otlp:
            sending_queue:
              enabled: true
              num_consumers: 10
            tls:
              insecure: true
        resolver:
          k8s:
            ports:
            - 4317
            service: collector-servicegraph-collector.o11y
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 10s
          max_elapsed_time: 120s
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
        timeout: 30s
      otlphttp/grafanacloud:
        auth:
          authenticator: basicauth/grafanacloud
        endpoint: ${env:GRAFANA_OTLP_ENDPOINT}
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 1000
        timeout: 30s
        tls:
          insecure: false
        headers:
          User-Agent: "otel-collector/0.130.0"
        compression: gzip
    extensions:
      basicauth/grafanacloud:
        client_auth:
          password: ${env:GRAFANA_PASSWORD}
          username: ${env:GRAFANA_USERNAME}
      health_check:
        endpoint: 0.0.0.0:13133
        path: /
        check_collector_pipeline:
          enabled: true
          interval: 5m
          exporter_failure_threshold: 5
      zpages:
        endpoint: 0.0.0.0:55679
    processors:
      memory_limiter:
        check_interval: 1s
        limit_mib: 6000 # up to 80 % of pod resources
        spike_limit_mib: 1600
      batch/logs:
        send_batch_max_size: 2048
        send_batch_size: 1024
        timeout: 5s
      batch/metrics:
        send_batch_max_size: 8192
        send_batch_size: 8192
        timeout: 5s
      batch/traces:
        send_batch_max_size: 8192
        send_batch_size: 1024
        timeout: 1s
      resource/add_k8s_namespace_pod_uid_selfmonitoring:
        attributes:
        - action: upsert
          key: service.namespace
          value: ${env:K8S_NAMESPACE}
        - action: upsert
          key: service.name
          value: maas-otel-collector-trace-loadbalance
      resourcedetection:
        detectors: [env, system]
        timeout: 5s
        override: false
      resource/add_resource_info:
        attributes:
        - action: upsert
          key: service.version
          value: "0.133.0"
        - action: upsert
          key: collector.name
          value: "trace-loadbalance"
        - action: upsert
          key: collector.type
          value: "loadbalancer"
      # make sure not to drop any important metrics
      # instead provide more specific filtering to the metrics
      filter/drop_noisy_metrics:
        metrics:
          exclude:
            match_type: regexp
            metric_names:
            - ".*grpc_io.*"
            - ".*_bucket$"
            - ".*_count$"
            - ".*_sum$"
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        extract:
          metadata:
            - k8s.pod.name
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
          labels:
            - tag_name: k8s.pod.label.app
              key: app
              from: pod
            - tag_name: k8s.pod.label.version
              key: version
              from: pod
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
          - sources:
            - from: connection
      transform/set_standard_labels:
      # No need to set service.instance.id as attribute, this will be promoted as intance label for metrics
        log_statements:
          - set(resource.attributes["loki.resource.labels"], Concat(["deployment.environment", "service.name", "service.namespace", "service.instance.id", "otel_collector_environment", "cloud.platform", "cloud.datacenter"], ","))
          - set(resource.attributes["otel_collector_environment"], "${env:COLLECTOR_ENVIRONMENT}")
        trace_statements:
          - set(resource.attributes["otel_collector_environment"], "${env:COLLECTOR_ENVIRONMENT}")
          - set(resource.attributes["service.instance.id"], resource.attributes["k8s.pod.name"]) where resource.attributes["k8s.pod.name"] != nil
          - set(resource.attributes["service.instance.id"], "MISSING_POD_NAME") where resource.attributes["k8s.pod.name"] == nil
          - set(resource.attributes["k8s.cluster.name"], "${env:CLUSTER_NAME}")
      transform/drop_unneeded_resource_attributes:
        error_mode: ignore
        trace_statements:
          - context: resource
            statements:
              - delete_key(attributes, "k8s.pod.start_time")
              - delete_key(attributes, "os.description")
              - delete_key(attributes, "os.type")
              - delete_key(attributes, "process.command_args")
              - delete_key(attributes, "process.executable.path")
              - delete_key(attributes, "process.pid")
              - delete_key(attributes, "process.runtime.description")
              - delete_key(attributes, "process.runtime.name")
              - delete_key(attributes, "process.runtime.version")
              - delete_key(attributes, "container.id")
        metric_statements:
          - context: resource
            statements:
              - delete_key(attributes, "k8s.pod.start_time")
              - delete_key(attributes, "os.description")
              - delete_key(attributes, "os.type")
              - delete_key(attributes, "process.command_args")
              - delete_key(attributes, "process.executable.path")
              - delete_key(attributes, "process.pid")
              - delete_key(attributes, "process.runtime.description")
              - delete_key(attributes, "process.runtime.name")
              - delete_key(attributes, "process.runtime.version")
              - delete_key(attributes, "container.id")
        log_statements:
          - context: resource
            statements:
              - delete_key(attributes, "k8s.pod.start_time")
              - delete_key(attributes, "os.description")
              - delete_key(attributes, "os.type")
              - delete_key(attributes, "process.command_args")
              - delete_key(attributes, "process.executable.path")
              - delete_key(attributes, "process.pid")
              - delete_key(attributes, "process.runtime.description")
              - delete_key(attributes, "process.runtime.name")
              - delete_key(attributes, "process.runtime.version")
              - delete_key(attributes, "container.id")
    receivers:
      filelog/selfmonitoring_trace_loadbalance:
        include:
        - /var/log/pods/${env:K8S_NAMESPACE}_${env:K8S_POD_NAME}_${env:K8S_POD_UID}/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          output: crio-recombine
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: 2006-01-02T15:04:05.999999999Z07:00
            layout_type: gotime
            parse_from: attributes.time
          type: regex_parser
        - id: parser-containerd
          output: crio-recombine
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: regex_parser
        - id: parser-docker
          output: crio-recombine
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: json_parser
        - combine_field: attributes.log
          id: crio-recombine
          is_first_entry: attributes.log matches '\\d\\d\\d\\d\\-\\d\\d\\-'
          output: extract_metadata_from_filepath
          source_identifier: attributes["log.file.path"]
          type: recombine
        - cache:
            size: 128
          id: extract_metadata_from_filepath
          parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
          type: regex_parser
        - from: attributes.log
          to: body
          type: move
        - from: attributes.stream
          to: attributes["log.iostream"]
          type: move
        - from: attributes.container_name
          to: resource["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: resource["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: resource["k8s.pod.name"]
          type: move
        - from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
          type: move
        - from: attributes.uid
          to: resource["k8s.pod.uid"]
          type: move
        start_at: end
      otlp/workstream:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
            max_recv_msg_size_mib: 8
            max_concurrent_streams: 1000
            read_buffer_size: 524288
            write_buffer_size: 524288
            keepalive:
              server_parameters:
                max_connection_idle: 11s
                max_connection_age: 12s
                max_connection_age_grace: 13s
                time: 30s
                timeout: 5s
              enforcement_policy:
                min_time: 10s
                permit_without_stream: true
          http:
            endpoint: 0.0.0.0:4318
            cors:
              allowed_origins:
              - "http://*"
              - "https://*"
              allowed_headers:
              - "*"
              max_age: 7200
      prometheus/selfmonitoring_trace_loadbalance:
        config:
          scrape_configs:
          - job_name: collector-selfmonitoring-loadbalance
            scrape_interval: 60s
            static_configs:
            - targets:
              - 0.0.0.0:8888
            metric_relabel_configs:
            - source_labels: [__name__]
              regex: "otelcol_.*"
              action: keep
    service:
      extensions:
      - health_check
      - basicauth/grafanacloud
      - zpages
      pipelines:
        logs/selfmonitoring:
          exporters:
            - otlphttp/grafanacloud
          processors:
            - memory_limiter
            - resource/add_k8s_namespace_pod_uid_selfmonitoring
            - transform/set_standard_labels
            - transform/drop_unneeded_resource_attributes
            - batch/logs
          receivers:
            - filelog/selfmonitoring_trace_loadbalance
        metrics/selfmonitoring:
          exporters:
            - otlphttp/grafanacloud
          processors:
            - memory_limiter
            - resource/add_k8s_namespace_pod_uid_selfmonitoring
            - transform/set_standard_labels
            - transform/drop_unneeded_resource_attributes
            - filter/drop_noisy_metrics
            - batch/metrics
          receivers:
            - prometheus/selfmonitoring_trace_loadbalance
        traces/workstream:
          exporters:
            - loadbalancing/tailsampling
            - loadbalancing/servicegraph
            - loadbalancing/spanmetrics
          processors:
            - memory_limiter
            - resourcedetection
            - k8sattributes
            - transform/set_standard_labels
            - transform/drop_unneeded_resource_attributes
            - batch/traces
          receivers:
            - otlp/workstream
      telemetry:
        logs:
          level: INFO
          encoding: json
          output_paths: ["stdout"]
          error_output_paths: ["stderr"]
          sampling:
            initial: 100
            thereafter: 100
        metrics:
          level: detailed
          readers:
          - pull:
              exporter:
                prometheus:
                  host: 0.0.0.0
                  port: 8888

  replicas: 1
  resources:
    limits:
      memory: 8000Mi
    requests:
      cpu: "1"
      memory: 4000Mi  
  configVersions: 3
  daemonSetUpdateStrategy: {}
  deploymentUpdateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  env:
  - name: GOMEMLIMIT
    value: 7200MiB
  - name: CLUSTER_NAME
    value: monitoring-aks-01
  - name: WORKSTREAM_NAME
    valueFrom:
      configMapKeyRef:
        key: workstream_name
        name: dv-grafanacloud-settings
  - name: COLLECTOR_STAGE
    valueFrom:
      configMapKeyRef:
        key: collector_stage
        name: dv-grafanacloud-settings
  - name: COLLECTOR_ENVIRONMENT
    valueFrom:
      configMapKeyRef:
        key: collector_environment
        name: dv-grafanacloud-settings
  - name: GRAFANA_OTLP_ENDPOINT
    valueFrom:
      configMapKeyRef:
        key: otlp_endpoint
        name: dv-grafanacloud-settings
  - name: GRAFANA_USERNAME
    valueFrom:
      secretKeyRef:
        key: stack_username
        name: dv-grafanacloud-auth
  - name: GRAFANA_PASSWORD
    valueFrom:
      secretKeyRef:
        key: stack_password
        name: dv-grafanacloud-auth
  - name: K8S_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
  - name: K8S_POD_NAME
    valueFrom:
      fieldRef:
        fieldPath: metadata.name
  - name: K8S_POD_UID
    valueFrom:
      fieldRef:
        fieldPath: metadata.uid
  ingress:
    route: {}
  ipFamilyPolicy: SingleStack
  managementState: managed
  mode: deployment
  observability:
    metrics: {}
  podDnsConfig: {}
  upgradeStrategy: automatic
  volumeMounts:
  - mountPath: /var/log/pods
    name: varlogpods
    readOnly: true
  volumes:
  - hostPath:
      path: /var/log/pods
    name: varlogpods