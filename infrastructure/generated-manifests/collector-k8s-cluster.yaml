apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: collector-k8s-cluster
  namespace: o11y
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.133.0
  config:
    receivers:
      # Kubernetes cluster metrics (generates k8s.* names)
      k8s_cluster:
        auth_type: serviceAccount
        collection_interval: 10s
        node_conditions_to_report:
          - Ready
          - MemoryPressure
          - DiskPressure
          - PIDPressure
        distribution: kubernetes
        allocatable_types_to_report:
          - cpu
          - memory
          - ephemeral-storage
      
      # Prometheus metrics following Grafana Cloud convention
      prometheus:
        config:
          scrape_configs:
          # All Nodes, scraping their cAdvisor endpoint (integrations/kubernetes/cadvisor)
          - job_name: 'integrations/kubernetes/cadvisor'
            scheme: https
            tls_config:
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
            - role: node
            relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [__meta_kubernetes_node_name]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/$${1}/proxy/metrics/cadvisor
          
          # All Nodes, scraping their Kubelet metrics endpoint (integrations/kubernetes/kubelet)
          - job_name: 'integrations/kubernetes/kubelet'
            scheme: https
            tls_config:
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
            - role: node
            relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            - target_label: __address__
              replacement: kubernetes.default.svc:443
            - source_labels: [__meta_kubernetes_node_name]
              regex: (.+)
              target_label: __metrics_path__
              replacement: /api/v1/nodes/$${1}/proxy/metrics
            metric_relabel_configs:
            - source_labels: [__name__]
              action: keep
              regex: go_goroutines|kubelet_certificate_manager_client_expiration_renew_errors|kubelet_certificate_manager_client_ttl_seconds|kubelet_certificate_manager_server_ttl_seconds|kubelet_server_expiration_renew_errors|kubelet_cgroup_manager_duration_seconds_bucket|kubelet_cgroup_manager_duration_seconds_count|kubelet_node_config_error|kubelet_node_name|kubelet_pleg_relist_duration_seconds_bucket|kubelet_pleg_relist_duration_seconds_count|kubelet_pleg_relist_interval_seconds_bucket|kubelet_pod_start_duration_seconds_bucket|kubelet_pod_start_duration_seconds_count|kubelet_pod_worker_duration_seconds_bucket|kubelet_pod_worker_duration_seconds_count|kubelet_running_container_count|kubelet_running_containers|kubelet_running_pod_count|kubelet_running_pods|kubelet_runtime_operations_errors_total|kubelet_runtime_operations_total|kubelet_volume_stats_available_bytes|kubelet_volume_stats_capacity_bytes|kubelet_volume_stats_inodes|kubelet_volume_stats_inodes_free|kubelet_volume_stats_inodes_used|kubelet_volume_stats_used_bytes|kubernetes_build_info|namespace_workload_pod|process_cpu_seconds_total|process_resident_memory_bytes|rest_client_requests_total|storage_operation_duration_seconds_count|storage_operation_errors_total|volume_manager_total_volumes
          
          # All Pods with kube-state-metrics label (integrations/kubernetes/kube-state-metrics)
          - job_name: 'integrations/kubernetes/kube-state-metrics'
            kubernetes_sd_configs:
            - role: service
            relabel_configs:
            - source_labels: [__meta_kubernetes_service_name]
              action: keep
              regex: kube-state-metrics
            - source_labels: [__meta_kubernetes_service_port_name]
              action: keep
              regex: http-metrics
            metric_relabel_configs:
            - source_labels: [__name__]
              action: keep
              regex: kube_configmap_info|kube_configmap_metadata_resource_version|kube_cronjob.*|kube_daemonset.*|kube_deployment_metadata_generation|kube_deployment_spec_replicas|kube_deployment_status_condition|kube_deployment_status_observed_generation|kube_deployment_status_replicas_available|kube_deployment_status_replicas_updated|kube_horizontalpodautoscaler_spec_max_replicas|kube_horizontalpodautoscaler_spec_min_replicas|kube_horizontalpodautoscaler_status_current_replicas|kube_horizontalpodautoscaler_status_desired_replicas|kube_job.*|kube_namespace_status_phase|kube_node.*|kube_persistentvolume_status_phase|kube_persistentvolumeclaim_access_mode|kube_persistentvolumeclaim_info|kube_persistentvolumeclaim_labels|kube_persistentvolumeclaim_resource_requests_storage_bytes|kube_persistentvolumeclaim_status_phase|kube_pod_completion_time|kube_pod_container_info|kube_pod_container_resource_limits|kube_pod_container_resource_requests|kube_pod_container_status_last_terminated_reason|kube_pod_container_status_last_terminated_timestamp|kube_pod_container_status_restarts_total|kube_pod_container_status_waiting_reason|kube_pod_info|kube_pod_owner|kube_pod_restart_policy|kube_pod_spec_volumes_persistentvolumeclaims_info|kube_pod_start_time|kube_pod_status_phase|kube_pod_status_reason|kube_replicaset.*|kube_resourcequota|kube_secret_metadata_resource_version|kube_statefulset.*
          
          # Node exporter metrics are handled by collector-k8s-nodes DaemonSet
          
          # All collectors for self-monitoring
          - job_name: 'integrations/otel-collector'
            kubernetes_sd_configs:
            - role: pod
            relabel_configs:
            - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
              action: keep
              regex: opentelemetry-collector
            - source_labels: [__meta_kubernetes_pod_container_port_name]
              action: keep
              regex: monitoring
            metric_relabel_configs:
            - source_labels: [__name__]
              action: keep
              regex: otelcol_receiver_accepted_spans_total|otelcol_receiver_accepted_metric_points_total|otelcol_receiver_accepted_log_records_total|otelcol_receiver_refused_spans_total|otelcol_receiver_refused_metric_points_total|otelcol_receiver_refused_log_records_total|otelcol_processor_accepted_spans_total|otelcol_processor_accepted_metric_points_total|otelcol_processor_accepted_log_records_total|otelcol_processor_refused_spans_total|otelcol_processor_refused_metric_points_total|otelcol_processor_refused_log_records_total|otelcol_processor_dropped_spans_total|otelcol_processor_dropped_metric_points_total|otelcol_processor_dropped_log_records_total|otelcol_exporter_sent_spans_total|otelcol_exporter_sent_metric_points_total|otelcol_exporter_sent_log_records_total|otelcol_exporter_send_failed_spans_total|otelcol_exporter_send_failed_metric_points_total|otelcol_exporter_send_failed_log_records_total|otelcol_exporter_enqueue_failed_spans_total|otelcol_exporter_enqueue_failed_metric_points_total|otelcol_exporter_enqueue_failed_log_records_total|otelcol_process_memory_rss|otelcol_process_cpu_seconds|otelcol_processor_batch_batch_send_size_sum|otelcol_processor_batch_batch_send_size_count|otelcol_processor_batch_timeout_trigger_send_total|otelcol_processor_batch_batch_size_trigger_send_total|otelcol_exporter_queue_size|otelcol_exporter_queue_capacity|otelcol_loadbalancer_backend_outcome_total|otelcol_loadbalancer_backend_latency_bucket|otelcol_loadbalancer_num_backends|otelcol_processor_tail_sampling_sampling_decision_timer_latency_bucket|otelcol_processor_tail_sampling_sampling_decision_latency_bucket|otelcol_processor_tail_sampling_sampling_traces_on_memory_gauge|otelcol_processor_tail_sampling_new_trace_id_received_total|otelcol_processor_tail_sampling_sampling_decision_total|otelcol_spanmetrics_calls_total|otelcol_spanmetrics_latency_bucket|otelcol_servicegraph_total_edges|otelcol_servicegraph_expired_requests_total

    processors:
      # Recommended memory limiter configuration for production
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25

      # Add useful resource attributes
      resource:
        attributes:
        - key: cluster
          value: ${env:CLUSTER_NAME}
          action: insert
        - key: k8s.cluster.name
          value: ${env:CLUSTER_NAME}
          action: upsert
        - key: collector.name
          value: collector-k8s-cluster
          action: insert
        - key: collector.version
          value: 0.133.0
          action: insert

      # Set standard labels following Grafana Cloud conventions
      transform/set_standard_labels:
        metric_statements:
        - context: resource
          statements:
          - set(attributes["service.name"], "kubernetes") where attributes["service.name"] == nil
          - set(attributes["service.namespace"], attributes["k8s.namespace.name"]) where attributes["k8s.namespace.name"] != nil
          - set(attributes["service.instance.id"], attributes["k8s.pod.uid"]) where attributes["k8s.pod.uid"] != nil

      # Batch processor configuration
      batch:
        send_batch_size: 1000
        timeout: 10s
        send_batch_max_size: 1500

    exporters:
      # Primary Grafana Cloud export
      otlphttp/grafanacloud:
        endpoint: ${env:GRAFANA_OTLP_ENDPOINT}
        auth:
          authenticator: basicauth/grafanacloud

    extensions:
      # Basic auth for Grafana Cloud
      basicauth/grafanacloud:
        client_auth:
          username: ${env:GRAFANA_USERNAME}
          password: ${env:GRAFANA_PASSWORD}
      health_check:
        endpoint: 0.0.0.0:13133

    service:
      extensions: [basicauth/grafanacloud, health_check]
      pipelines:
        metrics:
          receivers: [k8s_cluster, prometheus]
          processors: [memory_limiter, resource, transform/set_standard_labels, batch]
          exporters: [otlphttp/grafanacloud]
      telemetry:
        logs:
          level: DEBUG
        metrics:
          level: detailed
          readers:
          - pull:
              exporter:
                prometheus:
                  host: 0.0.0.0
                  port: 8888

  # Deploy as StatefulSet for cluster-level metrics
  mode: statefulset
  replicas: 1
  
  # Service account with cluster permissions
  serviceAccount: otel-k8s-cluster
  
  # Mount allowlist ConfigMaps
  volumes:
  - name: allowlists
    configMap:
      name: otel-allowlists
  
  volumeMounts:
  - name: allowlists
    mountPath: /etc/allowlists
    readOnly: true
  
  env:
  - name: CLUSTER_NAME
    value: monitoring-aks-01
  - name: GOMEMLIMIT
    value: 900MiB
  - name: COLLECTOR_ENVIRONMENT
    value: "production"
  - name: GRAFANA_OTLP_ENDPOINT
    value: "https://otlp-gateway-prod-eu-west-3.grafana.net/otlp"
  - name: GRAFANA_USERNAME
    valueFrom:
      secretKeyRef:
        key: stack_username
        name: dv-grafanacloud-auth
  - name: GRAFANA_PASSWORD
    valueFrom:
      secretKeyRef:
        key: stack_password
        name: dv-grafanacloud-auth